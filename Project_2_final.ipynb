{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "089072f0-b9b7-42bb-a348-0aefb5c2d02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.metrics import classification_report\n",
    "# Use the MinMaxScaler to scale data between 0 and 1.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import os\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hvplot.pandas\n",
    "import alpaca_trade_api as tradeapi\n",
    "from pathlib import Path\n",
    "from pandas_datareader import data as wb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import required Keras modules\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Load .env environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"classkeys.env\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ae9130-8ed6-4324-bb7e-bfeab724d48f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30a236b0-9706-4d07-8055-834071f04128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Alpaca API key and secret\n",
    "alpaca_api_key = os.getenv(\"ALPACA_API_KEY\")\n",
    "alpaca_secret_key = os.getenv(\"ALPACA_SECRET_KEY\")\n",
    "\n",
    "# Create the Alpaca API object\n",
    "alpaca = tradeapi.REST(\n",
    "    alpaca_api_key,\n",
    "    alpaca_secret_key,\n",
    "    api_version=\"v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6addc336-627f-4b12-bef0-843fce01b7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    \"\"\"\n",
    "    This function accepts the column number for the features (X) and the target (y).\n",
    "    It chunks the data up with a rolling window of Xt - window to predict Xt.\n",
    "    It returns two numpy arrays of X and y.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window):\n",
    "        features = df.iloc[i : (i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3fddce5e-f4dd-46bb-9e70-c06930e352b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Stock ticker\n",
    "tickers = [\"FSR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94e3c24a-aa64-46ce-bf73-18674df5e63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_LSTM(t):\n",
    "    timestamp = datetime.now()\n",
    "    print(f\"Start running model for {t}\")\n",
    "    # Set the Stock ticker\n",
    "    tickers = [t]\n",
    "\n",
    "    # Set timeframe to '1D'\n",
    "    timeframe = \"1D\"\n",
    "\n",
    "    # Set start and end datetimes\n",
    "    start_date = pd.Timestamp(\"2022-01-11\", tz=\"America/New_York\").isoformat()\n",
    "    end_date = pd.Timestamp(\"2022-01-21\", tz=\"America/New_York\").isoformat()\n",
    "\n",
    "    # Get data for ticker\n",
    "    fsr_df = alpaca.get_barset(\n",
    "        tickers,\n",
    "        timeframe,\n",
    "        start=start_date,\n",
    "        end=end_date,\n",
    "        limit=1000,\n",
    "    ).df\n",
    "\n",
    "    df = fsr_df\n",
    "\n",
    "    # Creating the features (X) and target (y) data using the window_data() function.\n",
    "    window_size = 5\n",
    "\n",
    "    feature_column = 2\n",
    "    target_column = 2\n",
    "    X, y = window_data(df, window_size, feature_column, target_column)\n",
    "    print (f\"X sample values:\\n{X[:5]} \\n\")\n",
    "    print (f\"y sample values:\\n{y[:5]}\")\n",
    "\n",
    "    # Use 70% of the data for training and the remainder for testing\n",
    "    split = int(0.7 * len(X))\n",
    "    X_train = X[: split]\n",
    "    X_test = X[split:]\n",
    "    y_train = y[: split]\n",
    "    y_test = y[split:]\n",
    "\n",
    "\n",
    "    # Create a MinMaxScaler object\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Fit the MinMaxScaler object with the training feature data X_train\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # Scale the features training and testing sets\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Fit the MinMaxScaler object with the training target data y_train\n",
    "    scaler.fit(y_train)\n",
    "\n",
    "    # Scale the target training and testing sets\n",
    "    y_train = scaler.transform(y_train)\n",
    "    y_test = scaler.transform(y_test)\n",
    "\n",
    "    # Reshape the features for the model\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "    print (f\"X_train sample values:\\n{X_train[:5]} \\n\")\n",
    "    print (f\"X_test sample values:\\n{X_test[:5]}\")\n",
    "\n",
    "\n",
    "    # Define the LSTM RNN model.\n",
    "    model = Sequential()\n",
    "\n",
    "    number_units = 5\n",
    "    dropout_fraction = 0.2\n",
    "\n",
    "    # Layer 1\n",
    "    model.add(LSTM(\n",
    "        units=number_units,\n",
    "        return_sequences=True,\n",
    "        input_shape=(X_train.shape[1], 1))\n",
    "        )\n",
    "    model.add(Dropout(dropout_fraction))\n",
    "    # Layer 2\n",
    "    model.add(LSTM(units=number_units, return_sequences=True))\n",
    "    model.add(Dropout(dropout_fraction))\n",
    "    # Layer 3\n",
    "    model.add(LSTM(units=number_units))\n",
    "    model.add(Dropout(dropout_fraction))\n",
    "    # Output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=10, shuffle=False, batch_size=1, verbose=1)\n",
    "\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.evaluate(X_test, y_test)\n",
    "\n",
    "    # Make some predictions\n",
    "    predicted = model.predict(X_test)\n",
    "    # Recover the original prices instead of the scaled version\n",
    "    predicted_prices = scaler.inverse_transform(predicted)\n",
    "    real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "    # Create a DataFrame of Real and Predicted values\n",
    "    stocks = pd.DataFrame({\n",
    "        \"Real\": real_prices.ravel(),\n",
    "        \"Predicted\": predicted_prices.ravel()\n",
    "        }, index = df.index[-len(real_prices): ])\n",
    "    stocks.head()\n",
    "    \n",
    "    print(f\"Prediction for {t} is {predicted}.\")\n",
    "    print(\"Run time: \", datetime.now() - timestamp)\n",
    "    return stocks, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f263c24-203e-45a8-84c6-b7ff23ef43ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running model for FSR\n",
      "X sample values:\n",
      "[[15.16   15.4    14.98   14.2609 14.08  ]\n",
      " [15.4    14.98   14.2609 14.08   13.39  ]\n",
      " [14.98   14.2609 14.08   13.39   12.7   ]] \n",
      "\n",
      "y sample values:\n",
      "[[13.39]\n",
      " [12.7 ]\n",
      " [11.93]]\n",
      "X_train sample values:\n",
      "[[[0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[-0.75      ]\n",
      "  [-1.71214286]\n",
      "  [-0.25156446]\n",
      "  [-3.81426202]\n",
      "  [-1.        ]]]\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 3s 7ms/step - loss: 0.4818\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4571\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4620\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4530\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4706\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4560\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4869\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4786\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4163\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4332\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2376\n",
      "Prediction for FSR is [[-0.00347471]].\n",
      "Run time:  0:00:07.049760\n"
     ]
    }
   ],
   "source": [
    "# demo of the function, just to run once\n",
    "stockframe, prediction = run_LSTM(\"FSR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3c580f03-7762-4737-bd1e-9cd51074f0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FB', 'INTC', 'TWTR']\n",
      "['TSLA', 'NVDA', 'FSR']\n",
      "['MSFT', 'GOOGL', 'AMZN', 'AAPL']\n"
     ]
    }
   ],
   "source": [
    "# Set the Stock ticker\n",
    "tickers = [\"AMZN\" , \"TWTR\" , \"GOOGL\" , \"FB\" , \"MSFT\" , \"AAPL\" , \"TSLA\" , \"FSR\" , \"NVDA\" , \"INTC\"]\n",
    "\n",
    "# Set timeframe to '1D'\n",
    "timeframe = \"1D\"\n",
    "\n",
    "# Set start and end datetimes\n",
    "start_date = pd.Timestamp(\"2020-01-02\", tz=\"America/New_York\").isoformat()\n",
    "end_date = pd.Timestamp(\"2022-01-21\", tz=\"America/New_York\").isoformat()\n",
    "\n",
    "# Get data for aamzn ticker\n",
    "stock_df = alpaca.get_barset(\n",
    "    tickers,\n",
    "    timeframe,\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    "    limit=1000,\n",
    ").df\n",
    "stock_df.head()\n",
    "\n",
    "# Daily  returns contain closing price of all stock\n",
    "nvda_closing_prices = pd.DataFrame()\n",
    "\n",
    "# fetch closing prices\n",
    "nvda_closing_prices[\"NVDA\"] = stock_df[\"NVDA\"][\"close\"]\n",
    "\n",
    "# Drop the time component of the date\n",
    "nvda_closing_prices.index = nvda_closing_prices.index.date\n",
    "\n",
    "# Compute daily returns\n",
    "nvda_daily_returns = nvda_closing_prices.pct_change().dropna()\n",
    "nvda_daily_returns.head()\n",
    "\n",
    "# Create and empty DataFrame for closing prices\n",
    "amzn_closing_prices = pd.DataFrame()\n",
    "\n",
    "# fetch closing prices\n",
    "amzn_closing_prices[\"AMZN\"] = stock_df[\"AMZN\"][\"close\"]\n",
    "\n",
    "# Drop the time component of the date\n",
    "amzn_closing_prices.index = amzn_closing_prices.index.date\n",
    "\n",
    "# Compute daily returns\n",
    "amzn_daily_returns = amzn_closing_prices.pct_change().dropna()\n",
    "amzn_daily_returns.head()\n",
    "\n",
    "# Create and empty DataFrame for closing prices\n",
    "aapl_closing_prices = pd.DataFrame()\n",
    "\n",
    "# fetch closing prices\n",
    "aapl_closing_prices[\"AAPL\"] = stock_df[\"AAPL\"][\"close\"]\n",
    "\n",
    "# Drop the time component of the date\n",
    "aapl_closing_prices.index = aapl_closing_prices.index.date\n",
    "\n",
    "# Compute daily returns\n",
    "aapl_daily_returns = aapl_closing_prices.pct_change().dropna()\n",
    "aapl_daily_returns.head()\n",
    "\n",
    "# Create and empty DataFrame for closing prices\n",
    "tsla_closing_prices = pd.DataFrame()\n",
    "\n",
    "# fetch closing prices\n",
    "tsla_closing_prices[\"TSLA\"] = stock_df[\"TSLA\"][\"close\"]\n",
    "\n",
    "# Drop the time component of the date\n",
    "tsla_closing_prices.index = tsla_closing_prices.index.date\n",
    "\n",
    "# Compute daily returns\n",
    "tsla_daily_returns = tsla_closing_prices.pct_change().dropna()\n",
    "tsla_daily_returns.head()\n",
    "\n",
    "# Create and empty DataFrame for closing prices\n",
    "googl_closing_prices = pd.DataFrame()\n",
    "\n",
    "# fetch closing prices\n",
    "googl_closing_prices[\"GOOGL\"] = stock_df[\"GOOGL\"][\"close\"]\n",
    "\n",
    "# Drop the time component of the date\n",
    "googl_closing_prices.index = googl_closing_prices.index.date\n",
    "\n",
    "# Compute daily returns\n",
    "googl_daily_returns = googl_closing_prices.pct_change().dropna()\n",
    "googl_daily_returns.head()\n",
    "\n",
    "# Create and empty DataFrame for closing prices\n",
    "fb_closing_prices = pd.DataFrame()\n",
    "\n",
    "# fetch closing prices\n",
    "fb_closing_prices[\"FB\"] = stock_df[\"FB\"][\"close\"]\n",
    "\n",
    "# Drop the time component of the date\n",
    "fb_closing_prices.index = fb_closing_prices.index.date\n",
    "\n",
    "# Compute daily returns\n",
    "fb_daily_returns =fb_closing_prices.pct_change().dropna()\n",
    "fb_daily_returns.head()\n",
    "\n",
    "# Create and empty DataFrame for closing prices\n",
    "msft_closing_prices = pd.DataFrame()\n",
    "\n",
    "# fetch closing prices\n",
    "msft_closing_prices[\"MSFT\"] = stock_df[\"MSFT\"][\"close\"]\n",
    "\n",
    "# Drop the time component of the date\n",
    "msft_closing_prices.index = msft_closing_prices.index.date\n",
    "\n",
    "# Compute daily returns\n",
    "msft_daily_returns = msft_closing_prices.pct_change().dropna()\n",
    "msft_daily_returns.head()\n",
    "\n",
    "# Create and empty DataFrame for closing prices\n",
    "twtr_closing_prices = pd.DataFrame()\n",
    "\n",
    "# fetch closing prices\n",
    "twtr_closing_prices[\"TWTR\"] = stock_df[\"TWTR\"][\"close\"]\n",
    "\n",
    "# Drop the time component of the date\n",
    "twtr_closing_prices.index =twtr_closing_prices.index.date\n",
    "\n",
    "# Compute daily returns\n",
    "twtr_daily_returns = twtr_closing_prices.pct_change().dropna()\n",
    "twtr_daily_returns.head()\n",
    "\n",
    "# Create and empty DataFrame for closing prices\n",
    "fsr_closing_prices = pd.DataFrame()\n",
    "\n",
    "# fetch closing prices\n",
    "fsr_closing_prices[\"FSR\"] = stock_df[\"FSR\"][\"close\"]\n",
    "\n",
    "# Drop the time component of the date\n",
    "fsr_closing_prices.index =fsr_closing_prices.index.date\n",
    "\n",
    "# Compute daily returns\n",
    "fsr_daily_returns = fsr_closing_prices.pct_change().dropna()\n",
    "fsr_daily_returns.head()\n",
    "\n",
    "# Create and empty DataFrame for closing prices\n",
    "intc_closing_prices = pd.DataFrame()\n",
    "\n",
    "# fetch closing prices\n",
    "intc_closing_prices[\"INTC\"] = stock_df[\"INTC\"][\"close\"]\n",
    "\n",
    "# Drop the time component of the date\n",
    "intc_closing_prices.index =intc_closing_prices.index.date\n",
    "\n",
    "# Compute daily returns\n",
    "intc_daily_returns = intc_closing_prices.pct_change().dropna()\n",
    "intc_daily_returns.head()\n",
    "\n",
    "\n",
    "stock_daily_returns_df = pd.concat([intc_daily_returns,fsr_daily_returns, twtr_daily_returns, msft_daily_returns, aapl_daily_returns, amzn_daily_returns, googl_daily_returns, tsla_daily_returns, fb_daily_returns, nvda_daily_returns], axis=1, join=\"inner\")\n",
    "\n",
    "# Calculating volatility\n",
    "volatility = stock_daily_returns_df.std().sort_values()\n",
    "\n",
    "# Splitting up the list of stocks by sorted volatilities\n",
    "split = round(len(volatility) / 3) \n",
    "\n",
    "high = volatility[len(volatility) - split:]\n",
    "mid = volatility[len(volatility) - 2 * split :len(volatility) - split]\n",
    "low = volatility[:len(volatility) - 2 * split]\n",
    "\n",
    "mid_list = mid.index.tolist()\n",
    "print(mid_list)\n",
    "\n",
    "high_list = high.index.tolist()\n",
    "print(high_list)\n",
    "\n",
    "low_list = low.index.tolist()\n",
    "print(low_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "112750de-cc8c-4f90-8bef-f3d09b6f5cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_stocks = [\"AMZN\" , \"TWTR\" , \"GOOGL\" , \"FB\" , \"MSFT\" , \"AAPL\" , \"TSLA\" , \"FSR\" , \"NVDA\" , \"INTC\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64cdbee2-b1a4-4f5d-90ac-2ee22b4b8a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running model for AMZN\n",
      "X sample values:\n",
      "[[3215.28 3288.34 3221.82 3196.01 3153.29]\n",
      " [3288.34 3221.82 3196.01 3153.29 3125.  ]\n",
      " [3221.82 3196.01 3153.29 3125.   3027.02]] \n",
      "\n",
      "y sample values:\n",
      "[[3125.   ]\n",
      " [3027.02 ]\n",
      " [2841.408]]\n",
      "X_train sample values:\n",
      "[[[0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[ 0.08951547]\n",
      "  [-0.38800361]\n",
      "  [-1.65517241]\n",
      "  [-0.6622191 ]\n",
      "  [-3.46341463]]]\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 3s 16ms/step - loss: 0.5589\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5739\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4933\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5366\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5416\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5170\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5217\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4847\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5109\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4922\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x00000261B6855E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.8903\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000261BF70EB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Prediction for AMZN is [[0.07799679]].\n",
      "Run time:  0:00:07.266029\n",
      "Start running model for TWTR\n",
      "X sample values:\n",
      "[[39.635 39.77  38.61  37.51  37.13 ]\n",
      " [39.77  38.61  37.51  37.13  37.005]\n",
      " [38.61  37.51  37.13  37.005 37.195]] \n",
      "\n",
      "y sample values:\n",
      "[[37.005]\n",
      " [37.195]\n",
      " [34.795]]\n",
      "X_train sample values:\n",
      "[[[0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[-7.59259259]\n",
      "  [-0.94827586]\n",
      "  [-0.34545455]\n",
      "  [-0.32894737]\n",
      "  [ 1.52      ]]]\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 5s 4ms/step - loss: 0.4985\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4812\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4884\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4893\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4860\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4742\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4903\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4514\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4488\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4545\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x00000261ADCD6790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 979ms/step - loss: 133.9677\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000261ADB22DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Prediction for TWTR is [[-0.05713648]].\n",
      "Run time:  0:00:07.932983\n",
      "Start running model for GOOGL\n",
      "X sample values:\n",
      "[[2733.845  2813.89   2768.18   2739.97   2708.765 ]\n",
      " [2813.89   2768.18   2739.97   2708.765  2700.31  ]\n",
      " [2768.18   2739.97   2708.765  2700.31   2659.2932]] \n",
      "\n",
      "y sample values:\n",
      "[[2700.31  ]\n",
      " [2659.2932]\n",
      " [2601.73  ]]\n",
      "X_train sample values:\n",
      "[[[0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[ 0.42894622]\n",
      "  [-0.61715161]\n",
      "  [-1.10616803]\n",
      "  [-0.27095017]\n",
      "  [-4.85118865]]]\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 3s 7ms/step - loss: 0.5058\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4952\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4851\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4789\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4591\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4890\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.4851\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4652\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4435\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4380\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.0562\n",
      "Prediction for GOOGL is [[0.0305558]].\n",
      "Run time:  0:00:07.232870\n",
      "Start running model for FB\n",
      "X sample values:\n",
      "[[325.28 330.03 325.76 321.21 317.64]\n",
      " [330.03 325.76 321.21 317.64 319.33]\n",
      " [325.76 321.21 317.64 319.33 315.98]] \n",
      "\n",
      "y sample values:\n",
      "[[319.33]\n",
      " [315.98]\n",
      " [303.04]]\n",
      "X_train sample values:\n",
      "[[[0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[ 0.10105263]\n",
      "  [-1.06557377]\n",
      "  [-0.78461538]\n",
      "  [ 0.47338936]\n",
      "  [-0.98224852]]]\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 6s 4ms/step - loss: 0.4991\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4873\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4622\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5006\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4456\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4663\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4452\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4276\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3931\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4512\n",
      "1/1 [==============================] - 2s 2s/step - loss: 15.1267\n",
      "Prediction for FB is [[0.02661868]].\n",
      "Run time:  0:00:10.739366\n",
      "Start running model for MSFT\n",
      "X sample values:\n",
      "[[309.89 317.08 304.   303.75 301.74]\n",
      " [317.08 304.   303.75 301.74 302.7 ]\n",
      " [304.   303.75 301.74 302.7  301.14]] \n",
      "\n",
      "y sample values:\n",
      "[[302.7 ]\n",
      " [301.14]\n",
      " [295.61]]\n",
      "X_train sample values:\n",
      "[[[0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[-0.81919332]\n",
      "  [-0.01911315]\n",
      "  [-8.04      ]\n",
      "  [ 0.47761194]\n",
      "  [-0.625     ]]]\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 6s 18ms/step - loss: 0.4690\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4589\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4715\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4358\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4265\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4371\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4965\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4316\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4253\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4347\n",
      "1/1 [==============================] - 1s 1s/step - loss: 12.6271\n",
      "Prediction for MSFT is [[0.00859745]].\n",
      "Run time:  0:00:08.574386\n",
      "Start running model for AAPL\n",
      "X sample values:\n",
      "[[170.82  174.82  171.79  171.09  169.405]\n",
      " [174.82  171.79  171.09  169.405 165.94 ]\n",
      " [171.79  171.09  169.405 165.94  164.18 ]] \n",
      "\n",
      "y sample values:\n",
      "[[165.94]\n",
      " [164.18]\n",
      " [162.3 ]]\n",
      "X_train sample values:\n",
      "[[[0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[ 0.2425    ]\n",
      "  [-0.2310231 ]\n",
      "  [-2.40714286]\n",
      "  [-2.05637982]\n",
      "  [-0.50793651]]]\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 5s 13ms/step - loss: 0.4908\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4798\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4583\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4419\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4507\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4183\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4199\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4010\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4100\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4325\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1811\n",
      "Prediction for AAPL is [[0.01860422]].\n",
      "Run time:  0:00:09.234301\n",
      "Start running model for TSLA\n",
      "X sample values:\n",
      "[[1038.82   1072.5901 1026.5391 1013.3788 1016.06  ]\n",
      " [1072.5901 1026.5391 1013.3788 1016.06    995.    ]\n",
      " [1026.5391 1013.3788 1016.06    995.      994.    ]] \n",
      "\n",
      "y sample values:\n",
      "[[995. ]\n",
      " [994. ]\n",
      " [940.5]]\n",
      "X_train sample values:\n",
      "[[[0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[-0.36366194]\n",
      "  [-0.28577664]\n",
      "  [ 0.20373396]\n",
      "  [-6.85469193]\n",
      "  [-0.04748338]]]\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 4s 6ms/step - loss: 0.4783\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4950\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4879\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4775\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4625\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4760\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4748\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4510\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4433\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4652\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2866.8000\n",
      "Prediction for TSLA is [[0.04250808]].\n",
      "Run time:  0:00:08.939800\n",
      "Start running model for FSR\n",
      "X sample values:\n",
      "[[15.23   15.4    14.98   14.2609 14.08  ]\n",
      " [15.4    14.98   14.2609 14.08   13.39  ]\n",
      " [14.98   14.2609 14.08   13.39   12.7   ]] \n",
      "\n",
      "y sample values:\n",
      "[[13.39]\n",
      " [12.7 ]\n",
      " [11.93]]\n",
      "X_train sample values:\n",
      "[[[0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[-1.47058824]\n",
      "  [-1.71214286]\n",
      "  [-0.25156446]\n",
      "  [-3.81426202]\n",
      "  [-1.        ]]]\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 4s 5ms/step - loss: 0.5307\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5378\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4846\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5263\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4759\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4864\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4681\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4802\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4611\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4749\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4174\n",
      "Prediction for FSR is [[0.07462062]].\n",
      "Run time:  0:00:07.192638\n",
      "Start running model for NVDA\n",
      "X sample values:\n",
      "[[268.39   276.08   264.98   262.1001 257.7   ]\n",
      " [276.08   264.98   262.1001 257.7    250.52  ]\n",
      " [264.98   262.1001 257.7    250.52   240.78  ]] \n",
      "\n",
      "y sample values:\n",
      "[[250.52]\n",
      " [240.78]\n",
      " [232.63]]\n",
      "X_train sample values:\n",
      "[[[0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[-0.44343303]\n",
      "  [-0.25945045]\n",
      "  [-1.52786555]\n",
      "  [-1.6317811 ]\n",
      "  [-1.35654596]]]\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 6s 6ms/step - loss: 0.5305\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5049\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5286\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4893\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5193\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4614\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4380\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4741\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4260\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4586\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8302\n",
      "Prediction for NVDA is [[0.07439722]].\n",
      "Run time:  0:00:09.261337\n",
      "Start running model for INTC\n",
      "X sample values:\n",
      "[[54.735 54.81  54.77  54.53  54.68 ]\n",
      " [54.81  54.77  54.53  54.68  53.56 ]\n",
      " [54.77  54.53  54.68  53.56  51.94 ]] \n",
      "\n",
      "y sample values:\n",
      "[[53.56]\n",
      " [51.94]\n",
      " [51.95]]\n",
      "X_train sample values:\n",
      "[[[0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[ 0.46666667]\n",
      "  [-6.        ]\n",
      "  [ 0.625     ]\n",
      "  [-6.46666667]\n",
      "  [-1.44642857]]]\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 5s 5ms/step - loss: 0.4901\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4752\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4645\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4515\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4803\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4497\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.4662\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4643\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4305\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4273\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0025\n",
      "Prediction for INTC is [[-0.04345708]].\n",
      "Run time:  0:00:08.200339\n"
     ]
    }
   ],
   "source": [
    "Collection = dict()\n",
    "\n",
    "for i in tech_stocks:\n",
    "    stockframe, prediction = run_LSTM(i)\n",
    "    Collection[i] = [stockframe, prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5edf9bad-efa2-4dc2-ab65-b7d379ea5a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMZN\n",
      "TWTR\n",
      "GOOGL\n",
      "FB\n",
      "MSFT\n",
      "AAPL\n",
      "TSLA\n",
      "FSR\n",
      "NVDA\n",
      "INTC\n"
     ]
    }
   ],
   "source": [
    "for key in Collection:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ade4a318-8d67-4a84-ab2e-cdaff295d336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-21 00:00:00-05:00</th>\n",
       "      <td>295.61</td>\n",
       "      <td>301.153412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Real   Predicted\n",
       "time                                         \n",
       "2022-01-21 00:00:00-05:00  295.61  301.153412"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Collection['MSFT'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "886fe6fa-cfab-4d21-9da4-974868cdd476",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_frames = []\n",
    "\n",
    "for i in Collection:\n",
    "    df = Collection[i][0].copy()\n",
    "    df['ticker'] = i\n",
    "    extract_frames.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45aa2c79-310a-4d62-9161-c8626d84d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat(extract_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b941c40a-f593-48e6-8036-1e6f1af0464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.rename(columns = {\n",
    "    'Real' : \"Today's Actuals\",\n",
    "    'Predicted' : \"Tomorrow's Prediction\",\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "40f892d0-11fd-4df9-8447-e08c8ef37019",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['Predicted Returns'] = (result_df[\"Tomorrow's Prediction\"] - result_df[\"Today's Actuals\"]) / result_df[\"Today's Actuals\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0edabf8a-a0d7-41f7-870f-13c86160668c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>Today's Actuals</th>\n",
       "      <th>Tomorrow's Prediction</th>\n",
       "      <th>ticker</th>\n",
       "      <th>Predicted Returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-21 00:00:00-05:00</td>\n",
       "      <td>2841.408</td>\n",
       "      <td>3034.662109</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.068014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-21 00:00:00-05:00</td>\n",
       "      <td>34.795</td>\n",
       "      <td>36.994144</td>\n",
       "      <td>TWTR</td>\n",
       "      <td>0.063203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-21 00:00:00-05:00</td>\n",
       "      <td>2601.730</td>\n",
       "      <td>2660.546387</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>0.022607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-21 00:00:00-05:00</td>\n",
       "      <td>303.040</td>\n",
       "      <td>316.069183</td>\n",
       "      <td>FB</td>\n",
       "      <td>0.042995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-21 00:00:00-05:00</td>\n",
       "      <td>295.610</td>\n",
       "      <td>301.153412</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.018752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time  Today's Actuals  Tomorrow's Prediction ticker  \\\n",
       "0 2022-01-21 00:00:00-05:00         2841.408            3034.662109   AMZN   \n",
       "1 2022-01-21 00:00:00-05:00           34.795              36.994144   TWTR   \n",
       "2 2022-01-21 00:00:00-05:00         2601.730            2660.546387  GOOGL   \n",
       "3 2022-01-21 00:00:00-05:00          303.040             316.069183     FB   \n",
       "4 2022-01-21 00:00:00-05:00          295.610             301.153412   MSFT   \n",
       "\n",
       "   Predicted Returns  \n",
       "0           0.068014  \n",
       "1           0.063203  \n",
       "2           0.022607  \n",
       "3           0.042995  \n",
       "4           0.018752  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = result_df.reset_index()\n",
    "result_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e6ea97e3-e4c5-46b9-9288-2a7caf4a64a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = result_df[result_df['Predicted Returns'] == result_df['Predicted Returns'].max()].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c98d1a51-08e0-48bd-bf54-3aa32e5b01f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_suggestion = result_df.loc[location, \"ticker\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0a9908b9-fd0b-4f3a-825d-a01a4c733c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your risk tolerance from our survey analytics, we are recommending you to buy FSR now and sell it tomorrow.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Based on your risk tolerance from our survey analytics, we are recommending you to buy {ticker_suggestion} now and sell it tomorrow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47fc9b1-3a83-45e2-ac9a-329ea4667765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
